---
title: "Team proj 1"
author: "Team 6 purple"
date: "9/17/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F)
knitr::opts_chunk$set(include = F)
knitr::opts_chunk$set(out.width = '50%')
knitr::opts_chunk$set(fig.align="center")
```

```{r library,message=FALSE}
library(tidyverse) # Data wrangling
library(ggplot2) # Plotting

# For logistic regression
library(arm)
library(car)
library(pROC)
library(e1071)
library(caret)
```

```{r import data}
# CHANGE DIRECTORY
#income <- read.table("C:/Users/renha/Desktop/IDS702/lalondedata.txt",header = TRUE,sep = ",",stringsAsFactors = FALSE,row.names = 'X')
income = read.table(file = "D:/MIDS/fall 2020/702 modeling/dataset/lalondedata.txt", header = T, sep = ",", dec = ".")
```

```{r}
# Change the variable to factor levels
income = income %>% mutate(
        inc78 = case_when(
                re78 == 0 ~ 0,
                re78 > 0 ~ 1 ))

# Change to factors, apply to part I and part II
income$treat <- as.factor(income$treat)
income$black <- as.factor(income$black)
income$hispan <- as.factor(income$hispan)
income$married <- as.factor(income$married)
income$nodegree <- as.factor(income$nodegree)


# Response variable for part I, change in income - continuous
income$change <- income$re78 - income$re74

# Response variable for part II, inc78_factor - binary
income$inc78_factor <- as.factor(income$inc78)
```

## **Part I**

### **1. Introduction**

It is common to believe that job training is efficient in boosting the earnings of disadvantaged workers. In 1970s, several experiments was conducted to explore the real impact of job training on wages, including the National Supported Work (NSW) Demonstration[1]. In the experiment, eligible workers were assigned to receive job training, and their incomes in 1973, 1974, and 1977 were recorded accordingly.  

This analysis's primary goal is to assess whether receiving job training has a significant effect on annual earnings and what is the range of the effect. Other considerations include whether this effect differs by demographic groups in terms of age, education, and racial identity. We're also interested in exploring other associations with wages.  

### **2. Data**

#### **2.1 Data Pre-Processing**

The original data set is accessed via the NSW Demonstration experiment with 614 non-empty observations. To explore the effect of getting job training on annual wage, we create a numeric variable 'change' to quantify the changes in earnings from 1974 to 1978.


#### **2.2 Exploratory Data Analysis**

#### **Response variable: change in wages**

The distribution of change in earnings follows an approximately normal distribution. Given the boxplot of change in terms of whether the worker gets the job training, we observe a different in the average amount of change in earnings. That is, compared to people without job training, people having job training tends to receive larger increase in income in 1978.  

```{r}
# Check the distribution of change
#hist(income$change)
```

#### **Response variable vs other variables**
```{r}
# continuous
#pairs(income[,-c(1,4,5,6,7,11)])# Multicollinearity check?
# Could add a line y=0
#plot(income$age,income$edu)# ?? examine interaction?
#plot(income$age,income$change)
#plot(income$educ,income$change)
```

here's an interesting association between married and change because the difference in mean in the boxplot suggests a decrease in wage when the workers get married compared to those who do not. In terms of numeric variable, the scatter plot between change and age indicates a negative correlated pattern that the average change in wage decreases as the age increases. We will fit both predictors in the model selection process to explore the significance of the effect.

#### **Interactions effect**

```{r}
ggplot(data= income, aes(x=treat, y=change)) + geom_boxplot() 

ggplot(data= income, aes(x=as.factor(educ), y=change)) + geom_boxplot() + facet_wrap(~treat)
ggplot(data= income, aes(x=black, y=change)) + geom_boxplot() + facet_wrap(~treat) # interaction black:treat
ggplot(data= income, aes(x=hispan, y=change)) + geom_boxplot() + facet_wrap(~treat) 
ggplot(data= income, aes(x=married, y=change)) + geom_boxplot() + facet_wrap(~treat) # interaction married:treat
ggplot(data= income, aes(x=nodegree, y=change)) + geom_boxplot() + facet_wrap(~treat) 
ggplot(data= income, aes(x=treat, y=change)) + geom_boxplot() + facet_wrap(~nodegree) # nodegree:treat 
```

```{r,include=TRUE,message=F}
ggplot(data= income, aes(x=age, y=change)) + 
  geom_point() + geom_smooth(method = 'lm') + facet_wrap(~treat) +
  theme_classic()+
  ggtitle("Interaction: How the effect of treat differs by age")# age:treat
```

Interaction effects occur when the impact of one variable depends on the value of another variable. In this case, we explore the impact of demographic groups on the association between receiving job training and increasing wages using faced scatter plot and fitted line.  

Given whether the participants received job training, the correlation between non-zero wage and age changes from negative to positive. The difference indicates that workers without job training tend to receive a decrease in earnings as they get older, while workers who received job training receive a net benefit from age and training as their income increases as they grow in age. To draw a solid conclusion on interaction terms' impact, we will determine their efficiency in the modeling selection process.  

### **3. Model**

#### **3.1 Model Selection**

The model selection is based on two methods: AIC Stepwise Selection and ANOVA chi-square test.  

Applying stepwise selection on the full model with all potential predictor and a null model containing only treatment as a predictor, we are able to combine the forward and backward selection and pick the most significant variables by either adding or removing variables several times to meet the maximum likelihood estimation. The final stepwise regression we get includes three significant variables -- treatment, age and married. Additional variables and interaction terms is added to the existed model one by one and test their efficiency through the ANOVA Chi-square test.  

Given a p-value of 0.003 when compare the model with interactions between age and treatment vs. without, we reject the null hypothesis and confirm the interaction term efficient for predicting the changes in wages. Other individual predictors such as nodegree, Black and Hispanic performs poorly on ANOVA test, indicating insignificant effects on annual earning changes between 1974 and 1978.  

```{r}
raw <- lm(change~treat+age+educ+black+hispan+married+nodegree,data = income)
null <- lm(change~treat,data=income)
step(null,scope=formula(raw),direction="both",trace=0)
```

```{r}
fit1 <- lm(change~treat+age+married, data = income)
fit2 <- lm(change~treat+age+married+nodegree+nodegree:treat, data = income)
anova(fit1,fit2)
fit3 <- lm(change~treat+age+married+married:treat, data = income)
anova(fit1,fit3)
fit4 <- lm(change~treat+age+married+black, data = income)
anova(fit1,fit4)
fit5 <- lm(change~treat+age+married+black+black:treat, data = income)
anova(fit1,fit5)
fit6 <- lm(change~treat+age+married+nodegree, data = income)
anova(fit1,fit6)
fit7 <- lm(change~treat+age+married+treat:age, data = income)
anova(fit1,fit7)
```

#### **3.2 Final Model**

$$\widehat{Y}_{Change} = 6072.02 - 4586.31X_{treat:1}-135.79X_{age}-1756.52X_{married:1}+255.88X_{treat1:age}$$

In our final model, treatment, married, age and the interaction effects between age and treatments are four significant predictors for predicting the changes annual earnings from 1974 to 1978, using a threshold of 0.1. The R-square of the model is 0.074 which means that the model explains 7.4% of the variability in the data. 

*Association suggested by the final model*

 --- Keep other variables the same, compared to people without job training, people receiving job training, in average, encounter a 4586 decreases in annual earnings. Moreover, keeping other variables the same, one unit increase in age will result in a 135 dollar decreases in annual earnings from 1974 to 1978. However, the effect of job training changes as people get older. Worker with training get 255.88 dollar net increase in the annual wages when their age increases by one-unit, compared to those who does not receive the training. The net effect of age and treatment will shift from negative to positive after a certain age. [..........]
 
 --- There's a strong association between married and changes in annual wages. Keep other variables the constant, compared to people who did not get married, people who did, in average, tend to have 1756.52 dollars decrease in annual earnings. 



```{r}
ggplot(data = income,aes(x=age,y = fit7$residuals))+
         geom_point()+
         geom_smooth(method = 'lm')
plot(fit7, which = 1)
plot(fit7, which = 2)
n <- nrow(model.matrix(fit7))
p <- ncol(model.matrix(fit7))
lev_scores <- hatvalues(fit7)
plot(lev_scores,col=ifelse(lev_scores > (2*p/n), 'red2', 'navy'),type="h",
     ylab="Leverage score",xlab="Index",main="Leverage Scores for all observations")
text(x=c(1:n)[lev_scores > (2*p/n)]+c(rep(2,4),-2,2),y=lev_scores[lev_scores > (2*p/n)],
     labels=c(1:n)[lev_scores > (2*p/n)])
plot(fit7,which=4,col=c("blue4"))
threshhold = 2*(p+1)/n
abline(h=threshhold)
#plot(fit7,which=5,col=c("blue4"))
```

```{r,include=T}
pander::pander(fit7)
```
  
#### **3.3 Model Assessment**

```{r,include=T}
par(mfrow=c(2,2))
plot(fit7)
#confint(fit7, level = 0.9)
#confint(fit7, level = 0.95)
```
  
**VIF table for final model**  
  
```{r, include=T}
pander::pander(vif(fit7))
```

```{r}
cleaned <- income[-c(132,79,334),]
new <- lm(change~treat+age+married+treat:age, data = cleaned)
summary(new)
vif(new)
```

#### **3.4 Model Validation**

```{r}
set.seed(702) 
income <- income[sample(nrow(income)),]
K <- 10
RMSE1 <- matrix(0,nrow=K,ncol=1)
RMSE2 <- matrix(0,nrow=K,ncol=1)
kth_fold <- cut(seq(1,nrow(income)),breaks=K,labels=FALSE)
for(k in 1:K){
        test_index <- which(kth_fold==k)
        train <- income[-test_index,]
        test <- income[test_index,]
        test.fit1 <- lm(change~treat+age+married+treat:age, data = train)
        test.fit2 <- lm(change~treat+age+married, data = train)
        y_test_pred1 <- predict(test.fit1,test)
        y_test_pred2 <- predict(test.fit2,test)
        RMSE1[k,] <- sqrt(mean((test$change - (y_test_pred1))^2))
        RMSE2[k,] <- sqrt(mean((test$change - (y_test_pred2))^2))
}
mean(RMSE1)
mean(RMSE2)
```

#### **4. Conclusion**

## **Part II**

### **1. Introduction**

It is common to believe that job training is efficient in boosting the earnings of disadvantaged workers. In 1970s, several experiments was conducted to explore the real impact of job training on wages, including the National Supported Work (NSW) Demonstration[1]. In the experiment, eligible workers were assigned to receive job training, and their incomes in 1973, 1974, and 1977 were recorded accordingly.  

This analysis's primary goal is to assess whether receiving job training has a significant result in the possibility of receiving a non-zero wage. Other considerations include whether this effect differs by demographic groups in terms of age, education, and racial identity. We're also interested in exploring other associations with positive income.  

### **2. Data**

#### **2.1 Data Preprocessing**

The original data set is accessed via the NSW Demonstration experiment with 614 non-empty observations. Since this analysis features the possibility of getting a paid job, we create a binary variable 'inc78' where 0 represents zero wages, and 1 indicates positive income. The factorized variable 'inc78_factor' will be used as our response variable for analysis and modeling. The cleaned dataset included 6 categorical variables and 1 discrete variable.  

#### **2.2 Exploratory Data Analysis**

To get a general understanding of the baseline probability for model fitting and further analysis and examine the sufficiency of observations for both levels, we conduct a table of the response variables `inc78_factor`. According to the table, among the 614 participants, the average possibility of getting a non-zero wage job in 1978 is around 76%.  

#### **Response variable vs treat**

As an independent predictor, the treatment could be a reasonable predictor for predicting the possibility of having a non-zero income. Given the condition where a worker received job training, the conditional probability of getting positive pay decreases slightly compared to those who did not. However, according to the result of chi-square test (p-value = 0.77), the difference is not significant. Therefore, we need to exam the effect of treatment and possible interaction effects in the final model.  

#### **Response variable vs other predictors** 

Regarding other categorical variables, the association between Black and Non-zero income seems to be significant according to the conditional probability table. There's a lower conditional possibility of having non-zero wage when the worker's racial identity is Black, compared to workers in other racial groups. Even though there's a difference between the non-Hispanic and Hispanic groups, the change could result from insufficient observations on Hispanic workers. Since no significant change in the possibilities cross different levels is observed in 'married' and 'nondegree,' they might be pool predictor for predicting the non-zero wage rate. Still, possible interaction effects will be tested later.  

**Table for `inc78_factor` vs `treat`**  
```{r, include=T}
pander::pander(apply(table(income[,c("inc78_factor","treat")])/sum(table(income[,c("inc78_factor","treat")])),
      2,function(x) x/sum(x)))# need
```

```{r}
apply(table(income[,c("inc78_factor","black")])/sum(table(income[,c("inc78_factor","black")])),
      2,function(x) x/sum(x))
apply(table(income[,c("inc78_factor","hispan")])/sum(table(income[,c("inc78_factor","hispan")])),
      2,function(x) x/sum(x))
apply(table(income[,c("inc78_factor","married")])/sum(table(income[,c("inc78_factor","married")])),
      2,function(x) x/sum(x))
apply(table(income[,c("inc78_factor","nodegree")])/sum(table(income[,c("inc78_factor","nodegree")])),
      2,function(x) x/sum(x))
apply(table(income[,c("inc78_factor","educ")])/sum(table(income[,c("inc78_factor","educ")])),
      2,function(x) x/sum(x))
```

According to the boxplot analysis, the mean and range of age in the positive earning group is significantly higher zero income group. Given a chi-square test result of 0.002, we suggest a reasonable association between age and a positive wage. The possibility of getting non-zero earning decreases as the worker gets older, keeping everything else the same. However, considering the small sample size in different age groups, the effect of age on non-zero will be re-examed latter in modeling selection.  

#### **Interaction effect**

Interaction effects occur when the impact of one variable depends on the value of another variable. Conditional possibility tables and faceted boxplots are used to test the interaction effect between terms.  

Given whether the participants received job training, the visualized change on the correlation between non-zero wage and age indicates a possible interaction effect between treatment and age. The benefit of job training increases as the worker increases in age, and the net effects of training and age on the possibility of getting a non-zero wage shift from negative to zero, and possibly positive after a certain age.  

Another notable interaction is between age and degree as the association between inc78_factor and age change significantly, moving from groups with high school degrees to groups without. The possibility of getting paid employment tends to stay the same, and even increases as a worker with a high school degree grow older, while the possibility decrease as one without a high school degree.  

To draw a solid conclusion on interaction terms' impact, we will determine their efficiency in the modeling selection process.  

```{r,include=T}
ggplot(data= income, aes(x=age, y=inc78_factor,fill = treat)) + geom_boxplot() + facet_wrap(~treat) +
  theme_classic()+ggtitle('Interaction: how the effect of treat differs by age')# needed
```


```{r}
ggplot(data= income, aes(x=age, y=inc78_factor)) + geom_boxplot() + facet_wrap(~black)
ggplot(data= income, aes(x=age, y=inc78_factor)) + geom_boxplot() + facet_wrap(~hispan)
ggplot(data= income, aes(x=age, y=inc78_factor)) + geom_boxplot() + facet_wrap(~married)
ggplot(data= income, aes(x=age, y=inc78_factor)) + geom_boxplot() + facet_wrap(~nodegree)
```

```{r}
chisq.test(table(income[,c("nodegree","age")]))
chisq.test(table(income[,c("treat","educ")]))
chisq.test(table(income[,c("black","educ")]))
chisq.test(table(income[,c("married","educ")]))
chisq.test(table(income[,c("hispan","inc78_factor")])) # independent hispan inc78_factor
chisq.test(table(income[,c("black","inc78_factor")]))
chisq.test(table(income[,c("married","inc78_factor")])) # independent
chisq.test(table(income[,c("nodegree","inc78_factor")])) # independent

chisq.test(table(income[,c("hispan","age")])) # independent hispan age
chisq.test(table(income[,c("hispan","educ")]))
chisq.test(table(income[,c("hispan","black")]))
chisq.test(table(income[,c("hispan","nodegree")]))
chisq.test(table(income[,c("hispan","married")])) # independent hispan married
```

### **3. Model**

#### **3.1 Model Selection**

The model selection is based on two methods: AIC Stepwise Selection and ANOVA chi-square test.  

Applying stepwise selection on the full model with all potential predictor and a null model containing only treatment as a predictor, we are able to combine the forward and backward selection and pick the most significant variables by either adding or removing variables several times to meet the maximum likelihood estimation. At the end of the process, two significant variables -- age and black -- are selected. Stepwise selections manage large amounts of potential predictor variables and provide us a concise regression that allows us to add individual predictors and interaction effects later through the ANOVA test.  

Interaction terms between treatment and other variables were added to the full model one by one to explore the effect of demographic groups on the association between non-zero wage and job training. Given a p-value of 0.038 when we use ANOVA to compare the model with interactions between age and treatment vs. without, we reject the null hypothesis and confirm the interaction term efficient for predicting the possibility of getting a non-zero wage.   

Even though the interaction effect between age and high school degree seems significant in previous EDA, we failed to reject the null hypothesis and found the interaction term negligible. Other individual predictors such as nodegree, married and Hispanic have poor performance on ANOVA test, indicating insignificant effect on non-zero wages.  

```{r}
full <- glm(inc78_factor~treat+age+educ+black+hispan+married+nodegree+nodegree:age+treat:black+treat:hispan,family = binomial,data = income)
summary(full)
residFull <- residuals(full,"resp")
binnedplot(x=fitted(full),y=residFull,xlab="Pred. probabilities",col.int="red4",ylab="Avg. residuals",main="Binned residual plot",col.pts="navy") # 92% within SE band
```

```{r}
raw <- glm(inc78_factor~treat+age+educ+black+hispan+married+nodegree,family = binomial,data = income)
summary(raw)
```

```{r}
resid <- residuals(raw,"resp")
binnedplot(x=fitted(raw),y=resid,xlab="Pred. probabilities",col.int="red4",ylab="Avg. residuals",main="Binned residual plot",col.pts="navy") # 92% within SE band
```

```{r}
null <- glm(inc78_factor~treat,data=income,family=binomial)
selection <- step(null,scope=formula(full),direction="both",trace=0)
```

```{r}
fit1 <- glm(inc78_factor~treat+age+black,family = binomial,data = income)
anova(selection,fit1,test = 'Chisq')

fit2 <- glm(inc78_factor~age+treat*black,family = binomial,data = income)
anova(fit2,selection,test = 'Chisq')

fit3 <- glm(inc78_factor~age+black+treat*hispan,family = binomial,data = income)
anova(fit3,selection,test = 'Chisq')

fit4 <- glm(inc78_factor~black+treat*age,family = binomial,data = income)
anova(fit4,selection,test = 'Chisq') # treat:age significant

fit5 <- glm(inc78_factor~age+black+treat*educ,family = binomial,data = income)
anova(fit5,selection,test = 'Chisq')

fit6 <- glm(inc78_factor~age+black+treat*married,family = binomial,data = income)
anova(fit6,selection,test = 'Chisq')

fit7 <- glm(inc78_factor~age+black+treat*nodegree,family = binomial,data = income)
anova(fit7,selection,test = 'Chisq')

fit8 <- glm(inc78_factor~treat+black+age*nodegree,family = binomial,data = income)
anova(fit8,fit7,test = 'Chisq')

fit9 <- glm(inc78_factor~black+age*nodegree,family = binomial,data = income)
anova(fit9,selection,test = 'Chisq')
```

#### **3.2 Final Model**
```{r}
final <- glm(inc78_factor~black+treat*age,family = binomial,data = income)
#final_ploy <- glm(inc78_factor~black+treat*age+poly(age,3),family = binomial,data = income)
vif(final)
summary(final)
exp(final$coefficients)
exp(confint(final,level = 0.9))
```

$$log(\dfrac{\pi_i}{1-\pi_i})=0.87X_{mrace:black}+0.47X_{mrace:mexican}+0.19X_{mrace:mix}+0.40X_{mrace:white}$$

#### **3.3 Model Assessment**

For the model assessment of existed model, we calculate the raw (response) residuals for fitted logistic regression and plot average residual versus average predicted probability (or average predictor value) for each bin to explore abnormal patterns. According to the binned residual plot, all the points fall between the red lines which represent a band expected 95% of the observations. Therefore, we confirmed the model assumption is not violated.  

Moreover, cook's distance is used to examine any potential outliers in the model. [........]  

Finally, variance inflation factors was used to confirm that no multicolinearity existed in the chosen model. As all the VIFs were confirmed to be below 5 except the interaction terms, the model was finalized and used for inference.  

```{r,include=T}
par(mfrow=c(2,1))
residold <- residuals(final,"resp")
binnedplot(x=fitted(final),y=residold,xlab="Pred. probabilities",col.int="red4",ylab="Avg. residuals",main="Binned residual plot",col.pts="navy") # 92% within SE band -> 95.8%
binnedplot(x=income$age,y=residold,xlab="Age",col.int="red4",ylab="Avg. residuals",main="Binned residual plot",col.pts="navy")
```

```{r,include=T}
pander::pander(vif(final))
```

#### **3.4 Model Validation**

For model validation, we used a 2x2 confusion matrix for evaluate the performance of out final model. According to the matrix, we got an accuracy of 0.77 which means 77% of the observation are correctly classified by the model. The sensitivity of the test reflects the probability that the prediction will be positive (having non-zero wage) among those who do have non-zero earnings. A 0.99 sensitivity indicates a great true-positive rate of the model. However, the model is less efficient for a correct accurate results when the worker does not have a positive earning since the specificity rate is very low.

To better understand the performance of the classifier over all possible thresholds, we generated a ROC curve by plotting the True Positive Rate (y-axis) against the False Positive Rate (x-axis). The highest accuracy we can observed from adjusting the threshold for assigning observations to the given class is 0.757.

```{r}
# Threshold = 0.5
anova(raw,final,test = 'Chisq')
Conf_mat <- confusionMatrix(as.factor(ifelse(fitted(final) >= 0.5, "1","0")),
                            as.factor(income$inc78_factor),positive = "1")
Conf_mat$table
Conf_mat$overall["Accuracy"];
Conf_mat$byClass[c("Sensitivity","Specificity")] #True positive rate and True negative rate
```

```{r}
# Threshold = mean level
Conf_mat <- confusionMatrix(as.factor(ifelse(fitted(final) >= mean(income$inc78), "1","0")),
                            as.factor(income$inc78_factor),positive = "1")
Conf_mat$table
Conf_mat$overall["Accuracy"];
Conf_mat$byClass[c("Sensitivity","Specificity")] #True positive rate and True negative rate
```

#### **ROC curve: final model vs model with all predictors**
```{r,warning=FALSE,message=FALSE,include=T}
# ROC curve
invisible(roc(income$inc78_factor,fitted(final),plot=T,print.thres="best",print.auc=T,legacy.axes=T,col="red3"))
invisible(roc(income$inc78_factor,fitted(raw),plot=T,legacy.axes=T,add=T,col="blue3"))
legend('bottomright', c('final','raw'),lty=c(1,1),
       lwd=c(2,2),col=c('red3','blue3'))
```

### **4. Conclusion**

